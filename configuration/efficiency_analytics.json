[
    {
        "type": "Usage Analytics",
        "typeDescription": "Comparison of the resources allocated for jobs to the measured usage. Each point in the plots corresponds to the jobs run by a particular user. Points higher on the y-axis correspond to users with more allocated usage. Points on the left hand side of the x-axis correspond to higher measured usage.",
        "analytics": [
            {
                "analytic": "CPU Usage",
                "description": "How busy were the CPU cores?",
                "title": "CPU Usage",
                "field": "avg_percent_cpu_idle",
                "statistics": [
                    "avg_percent_cpu_idle",
                    "wall_time"
                ],
                "statisticLabels": [
                    "Average CPU % Idle: Weighted by Core Hour",
                    "CPU Hours: Total"
                ],
                "statisticDescription": [
                    "<ul><li><b>Average CPU % Idle: Weighted by Core Hour:</b> The average CPU idle % weighted by core hours, over all jobs that were executing.</li></ul><ul><li><b>CPU Hours: Total:</b> The total core time, in hours.<br/><i>Core Time:</i> defined as the time between start and end time of execution for a particular job times the number of allocated cores.</li></ul>"
                ],
                "valueLabels": [
                    "%",
                    "Core Hours"
                ],
                "reversed": false,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p>The chart below shows the percentage of time that the CPU cores were idle compared to overall usage. Each point on the plot shows the data for the jobs for a particular user.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>Making sure jobs use the right number of CPU cores helps ensure that the compute resources are used efficiently.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>For typical compute intensive jobs, the overall CPU usage should be &gt; 90 % (i.e. CPU core idle &lt; 10 %). Consider requesting fewer CPU cores for future jobs, or adjust the configuration settings of the software to make use of all the cores that have been requested.</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "CPU User",
                    "metric": "wall_time",
                    "metricTitle": "CPU Hours",
                    "group_by" : "cpuuser",
                    "groupByTitle": "CPU User",
                    "rotate": true,
                    "arrowImg": "right_arrow.png",
                    "histogramHelpText": [
                        "<div class='text'>",
                        "<h6> What is this analytic? </h6>",
                        "<p>The chart below shows the percentage of time that the CPU cores were idle compared to overall usage.</p>",
                        "<h6> Why is this analytic important? </h6>",
                        "<p>Making sure jobs use the right number of CPU cores helps ensure that the compute resources are used efficiently.</p>",
                        "<h6> How do I improve future jobs? </h6>",
                        "<p>For typical compute intensive jobs, the overall CPU usage should be &gt; 90 % (i.e. CPU core idle &lt; 10 %). Consider requesting fewer CPU cores for future jobs, or adjust the configuration settings of the software to make use of all the cores that have been requested.</p>",
                        "</div>"
                    ]
                }
            },
            {
                "analytic": "GPU Usage",
                "description": "How busy were the GPU cores for GPU jobs?",
                "title": "GPU Usage",
                "field": "avg_percent_gpu_active",
                "statistics": [
                    "avg_percent_gpu_active",
                    "gpu_time"
                ],
                "statisticLabels": [
                    "Avg GPU % Active: Weighted by GPU Hour",
                    "GPU Hours: Total"
                ],
                "statisticDescription":  [
                    "<ul><li><b>Avg GPU active: weighted by gpu-hour: </b> The average GPU usage % weighted by gpu hours, over all jobs that were executing.</li></ul><ul><li><b>GPU Hours: Total</b> The total GPU time in hours for all jobs that were executing during the time period. The GPU time is calculated as the number of allocated GPU devices multiplied by the wall time of the job.</li></ul>"
                ],
                "valueLabels": [
                    "%",
                    "GPU Hours"
                ],
                "reversed": true,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p>The chart below shows the percentage of time that the GPUs were busy compared to overall usage. Each point on the plot shows the GPU jobs for a particular user.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>Making sure jobs use the right number of GPUs helps ensure that the compute resources are used efficiently.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>Try to ensure that the number of GPUs requested matches the number required. If a code is not using all GPUs adjust the configuration settings of the software to make use of all the requested GPUs or consider requesting fewer GPUs in future jobs. If you have jobs with 0% GPU usage, double check that the code is compiled correctly to make use of the GPUs and is not defaulting to CPU-only calculations.</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "GPU Usage",
                    "metric": "gpu_time",
                    "metricTitle": "GPU Hours Total",
                    "group_by" : "gpu_usage_bucketid",
                    "groupByTitle": "GPU Active Value",
                    "rotate": true,
                    "arrowImg": "right_arrow.png",
                    "histogramHelpText": [
                        "<div class='text'>",
                        "<h6> What is this analytic? </h6>",
                        "<p>The chart below shows the percentage of time that the GPUs were busy compared to overall usage.</p>",
                        "<h6> Why is this analytic important? </h6>",
                        "<p>Making sure jobs use the right number of GPUs helps ensure that the compute resources are used efficiently.</p>",
                        "<h6> How do I improve future jobs? </h6>",
                        "<p>Try to ensure that the number of GPUs requested matches the number required. If a code is not using all GPUs adjust the configuration settings of the software to make use of all the requested GPUs or consider requesting fewer GPUs in future jobs. If you have jobs with 0% GPU usage, double check that the code is compiled correctly to make use of the GPUs and is not defaulting to CPU-only calculations.</p>",
                        "</div>"
                    ]
                }
            },
            {
                "analytic": "Memory Usage",
                "description": "How much memory was used?",
                "title": "Memory Usage",
                "field": "avg_max_memory_per_core",
                "statistics": [
                    "avg_max_memory_per_core",
                    "wall_time"
                ],
                "statisticLabels": [
                    "Avg: Max % Memory: Weighted by Core Hour",
                    "CPU Hours: Total"
                ],
                "statisticDescription": [
                    "<ul><li><b>Avg: Max % Memory: weighted by core-hour: </b>The average job max memory usage percentage weighted by core-hour. Max Memory usage is defined as memory used / total available for the largest memory usage measured during the execution of the job.</li></ul><ul><li><b>CPU Hours: Total:</b> The total core time, in hours.<br/><i>Core Time:</i> defined as the time between start and end time of execution for a particular job times the number of allocated cores.</li></ul>"
                ],
                "valueLabels": [
                    "%",
                    "Core Hours"
                ],
                "reversed": true,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p>The chart below compares the highest memory usage for jobs to overall usage. A value of 100% Max Memory indicates that a job used all of the allocated memory at some point during the job. Each point on the plot shows jobs for a particular user.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>Matching the requested memory to the required memory helps to ensure that the compute resources are used efficiently.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>Try to aim to have the maximum memory for a job to be 60 - 80% of the total requested. If you have large memory requirements, consider submitting jobs in the large memory partition (if available). If your job has lower memory requirements, then specifying an accurate requested memory in the scheduler configuration parameters could reduce the wait time for jobs.</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "Memory Headroom",
                    "metric": "wall_time",
                    "metricTitle": "CPU Hours Total",
                    "group_by" : "max_mem",
                    "groupByTitle": "Peak Memory Usage (%)",
                    "rotate": true,
                    "arrowImg": "double_headed_arrow.png",
                    "histogramHelpText": [
                        "<div class='text'>",
                        "<h6> What is this analytic? </h6>",
                        "<p>The chart below shows core-hours binned by the peak memory usage. A value of 100% peak usage indicates that a job used all of the allocated memory at some point during the job.</p>",
                        "<h6> Why is this analytic important? </h6>",
                        "<p>Matching the requested memory to the required memory helps to ensure that the compute resources are used efficiently.</p>",
                        "<h6> How do I improve future jobs? </h6>",
                        "<p>Try to aim to have the maximum memory for a job to be 60 - 80% of the total requested. If you have large memory requirements, consider submitting jobs in the large memory partition (if available). If your job has lower memory requirements, then specifying an accurate requested memory in the scheduler configuration parameters could reduce the wait time for jobs.</p>",
                        "</div>"
                    ]
                }
            },
            {
                "analytic": "Homogeneity",
                "description": "How does the work rate vary during the job?",
                "title": "Homogeneity",
                "field": "avg_homogeneity",
                "statistics": [
                    "avg_homogeneity",
                    "wall_time"
                ],
                "statisticLabels": [
                    "Avg: Homogeneity: weighted by node-hour",
                    "CPU Hours: Total"
                ],
                "statisticDescription": [
                    "<ul><li><b>Avg: Homogeneity: weighted by node-hour: </b>The average homogeneity value weighted by node hour. The homogeneity is a measure of how uniform the work rate is over the lifetime of a job. Jobs with low homogeneity value (near 0) should be investigated to check if an error has caused data processing to stop prematurely. The work-rate of the job is estimated using the L1D cache load rate of the CPU cores assigned to the job. The detection algorithm tries to fit a step function to the L1D cache load rate and the homogeneity score is low if a step occurs well before the end of the job.</li></ul><ul><li><b>CPU Hours: Total:</b> The total core time, in hours.<br/><i>Core Time:</i> defined as the time between start and end time of execution for a particular job times the number of allocated cores.</li></ul>"
                ],
                "valueLabels": [
                    "%",
                    "Core Hours"
                ],
                "reversed": true,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p>The chart below shows the homogeneity verses usage. The homogeneity measures how uniform the work rate is of the job. A value near 0 means that the work rate fell dramatically during the job and stayed low.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>If the computational work of a job stops before the end, then the job will take longer to complete or take up resources that could be used by other jobs.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>If the job has an I/O stop at the end, check to see if it can be run in parallel. For compute jobs that have a serial step at the end consider using heterogeneous job steps (if the scheduler provides this feature).</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "Homogeneity",
                    "metric": "wall_time",
                    "metricTitle": "CPU Hours",
                    "group_by" : "homogeneity_bucket_id",
                    "groupByTitle": "Homogeneity",
                    "rotate": true,
                    "arrowImg": "right_arrow.png"
                }
            }
        ]
    },
    {
        "type": "Design Analytics",
        "typeDescription": "Are jobs are using resources in an efficient manner consistent with their design? Each point in the plots corresponds to the jobs run by a particular user. Points higher on the y-axis correspond to users with more allocated usage. Points on the left hand side of the x-axis correspond to more efficient usage.",
        "analytics": [
            {
                "analytic": "Wall Time Accuracy",
                "description": "Did the jobs request the correct amount of time?",
                "title": "Wall Time Accuracy",
                "field": "wall_time_accuracy",
                "statistics": [
                    "wall_time_accuracy",
                    "requested_wall_time"
                ],
                "statisticLabels": [
                    "Wall Time Accuracy",
                    "Wall Time Allocated"
                ],
                "statisticDescription": [
                    "<ul><li><b>Wall Time Accuracy: </b> The ratio of total job wall time to total requested wall time during the time period. The wall time and requested wall time contribution outside of the time period are not included in the calculation. The requested wall time is defined as the user requested linear time between start and end time for execution of a particular job.</li></ul><ul><li><b>Wall Hours: Requested: Total: </b>The total time, in hours, jobs requested for execution.</li></ul>"
                ],
                "valueLabels": [
                    "%",
                    "Hours"
                ],
                "reversed": true,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p> A measure of wall time used compared to the wall time requested.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>The closer the requested wall time is to the actual wall time the better the scheduler efficiency. You will likely see shorter wait times for your job to run if you provide an accurate wall time request.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>Try to set the requested wall time for future jobs to be close to the amount of time that you expect it to run.</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "Wall Time Accuracy",
                    "metric": "wall_time",
                    "metricTitle": "Core Hours",
                    "group_by" : "wall_time_accuracy_bucketid",
                    "groupByTitle": "Wall Time Accuracy Value",
                    "rotate": true,
                    "arrowImg": "right_arrow.png",
                    "histogramHelpText": [
                        "<div class='text'>",
                        "<h6> What is this analytic? </h6>",
                        "<p>The chart below shows core-hours binned by wall time accuracy. Wall time accuracy compares wall time used to requested. A value of 100% indicates that the job used all the requested time.</p>",
                        "<h6> Why is this analytic important? </h6>",
                        "<p>The closer the requested wall time is to the actual wall time the better the scheduler efficiency. You will likely see shorter wait times for your job to run if you provide an accurate wall time request.</p>",
                        "<h6> How do I improve future jobs? </h6>",
                        "<p>Try to set the requested wall time for future jobs to be close to the amount of time that you expect it to run.</p>",
                        "</div>"
                    ]
                }
            },
            {
                "analytic": "Short Job Count",
                "description": "What proportion of jobs are very short?",
                "title": "Short Jobs",
                "field": "job_count",
                "statistics": [
                    "job_count",
                    "job_count"
                ],
                "mandatoryFilters" : {"jobwalltime" : "[0,1]"},
                "statisticLabels": [
                    "Number of Short Jobs (&lt; 30s)",
                    "Total Number of Jobs Ended"
                ],
                "statisticDescription": [
                    "<ul><li><b>Number of Short Jobs(&lt; 30s): </b>Total number of jobs ended within the time period selected with a wall time of less than 30 seconds.</li></ul><ul><li><b>Total Number of Jobs Ended:</b> Total number of jobs ended within the time period selected.</li></ul>"
                ],
                "valueLabels": [
                    "Jobs",
                    "Jobs"
                ],
                "reversed": false,
                "realm": "SUPREMM",
                "documentation": [
                    "<div class='text'>",
                    "<h6> What is this analytic? </h6>",
                    "<p>The analytic identifies users who are running a large proportion of short jobs. The plot shows the number of short (&lt; 30 s) jobs compared to the total number of jobs for each user.</p>",
                    "<h6> Why is this analytic important? </h6>",
                    "<p>The load on the scheduler software increases with the total number of jobs that are tracked. There is also a fixed overhead for setup and teardown when jobs start and end, which is independent of the job's wall time. Excessive short jobs can cause scheduler slowness for all users of the cluster and under extreme circumstances cause job failures.</p>",
                    "<h6> How do I improve future jobs? </h6>",
                    "<p>Try to minimize the number of short running jobs. This can be accomplished by aggregating multiple tasks into a smaller number of longer-running jobs.</p>",
                    "</div>"
                ],
                "histogram": {
                    "title": "Job Wall Time",
                    "metric": "job_count",
                    "metricTitle": "Number of Jobs Ended",
                    "group_by" : "jobwalltime",
                    "groupByTitle": "Job Wall Time",
                    "rotate": true,
                    "arrowImg": "right_arrow.png",
                    "histogramHelpText": [
                        "<div class='text'>",
                        "<h6> What is this analytic? </h6>",
                        "<p>The chart below shows the number of jobs binned by job wall time.</p>",
                        "<h6> Why is this analytic important? </h6>",
                        "<p>The load on the scheduler software increases with the total number of jobs that are tracked. There is also a fixed overhead for setup and teardown when jobs start and end, which is independent of the job's wall time. Excessive short jobs can cause scheduler slowness for all users of the cluster and under extreme circumstances cause job failures.</p>",
                        "<h6> How do I improve future jobs? </h6>",
                        "<p>Try to minimize the number of short running jobs. This can be accomplished by aggregating multiple tasks into a smaller number of longer-running jobs.</p>",
                        "</div>"
                    ]
                }
            }
        ]
    }
]
